{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-13T18:33:02.265565Z",
     "start_time": "2020-02-13T18:33:00.211348Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/quentin/env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/quentin/env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/quentin/env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/quentin/env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/quentin/env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/quentin/env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import keras\n",
    "import os\n",
    "import re\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn import preprocessing, model_selection\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.datasets import make_circles\n",
    "from sklearn import datasets\n",
    "from tensorflow.keras.datasets import mnist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-13T18:33:02.282036Z",
     "start_time": "2020-02-13T18:33:02.268265Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_goodXy (X,y):\n",
    "    ynew = model.predict_classes(X)\n",
    "    X_good =[]\n",
    "    y_good=[]\n",
    "    for i in range(len(X)):\n",
    "        if (ynew[i]==0 and y[i]==1) or (ynew[i]==1 and y[i]==0):\n",
    "            print (\"error prediction for X=%s, Predicted=%s, Real=%s\"% (X[i], ynew[i], y[i]))\n",
    "        else :\n",
    "            X_good.append(X[i])\n",
    "            y_good.append(y[i])\n",
    "    return X_good,y_good        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-13T18:33:02.299211Z",
     "start_time": "2020-02-13T18:33:02.285314Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_result_layers(model,X):\n",
    "    result_layers=[]\n",
    "    for i in range (len(model.layers)-1):\n",
    "        hidden_layers= keras.backend.function(\n",
    "                [model.layers[0].input],   \n",
    "                [model.layers[i].output,] \n",
    "                )    \n",
    "        result_layers.append(hidden_layers([X_good])[0])  \n",
    "    return result_layers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-13T18:33:02.324742Z",
     "start_time": "2020-02-13T18:33:02.303088Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_result_layers(filename,X,y,result_layers):\n",
    "    f = open(filename, \"w\")\n",
    "    for nb_X in range (len(X)):\n",
    "        #my_string=\"\"\n",
    "        my_string=str(y[nb_X])+','\n",
    "        for nb_layers in range (len(model.layers)-1):\n",
    "            my_string+=\"<b>,\"\n",
    "            for j in range (len(result_layers[nb_layers][nb_X])):\n",
    "                my_string+=str(result_layers[nb_layers][nb_X][j])+','\n",
    "            my_string+=\"</b>,\"    \n",
    "        my_string=my_string [0:-1]\n",
    "        my_string+='\\n'\n",
    "        f.write(my_string)    \n",
    "    f.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iris dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-13T18:33:03.159174Z",
     "start_time": "2020-02-13T18:33:02.327414Z"
    }
   },
   "outputs": [],
   "source": [
    "url=\"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n",
    "names = ['SepalLengthCm', 'SepalWidthCm', \n",
    "         'PetalLengthCm', 'PetalWidthCm', \n",
    "         'Species']\n",
    "\n",
    "data = pd.read_csv(url, names=names)\n",
    "\n",
    "#Classification binaire sur Virginica et Setosa seulement\n",
    "data=data[data['Species'].isin(['Iris-virginica', 'Iris-setosa'])]\n",
    "\n",
    "i = 8\n",
    "data_to_predict = data[:i].reset_index(drop = True)\n",
    "predict_species = data_to_predict.Species \n",
    "predict_species = np.array(predict_species)\n",
    "prediction = np.array(data_to_predict.drop(['Species'],axis= 1))\n",
    "\n",
    "data = data[i:].reset_index(drop = True)\n",
    "\n",
    "X = data.drop(['Species'], axis = 1)\n",
    "X = np.array(X)\n",
    "y = data['Species']\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "y=encoder.fit_transform(y)\n",
    "\n",
    "\n",
    "train_X, test_X, train_y, test_y = model_selection.train_test_split(X,y,test_size = 0.1, random_state = 0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-13T18:33:04.678441Z",
     "start_time": "2020-02-13T18:33:03.161667Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "82/82 [==============================] - 1s 8ms/step - loss: 0.7044 - acc: 0.5610\n",
      "Epoch 2/10\n",
      "82/82 [==============================] - 0s 2ms/step - loss: 0.6161 - acc: 0.5610\n",
      "Epoch 3/10\n",
      "82/82 [==============================] - 0s 2ms/step - loss: 0.5516 - acc: 0.5610\n",
      "Epoch 4/10\n",
      "82/82 [==============================] - 0s 2ms/step - loss: 0.4480 - acc: 0.6829\n",
      "Epoch 5/10\n",
      "82/82 [==============================] - 0s 2ms/step - loss: 0.3425 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "82/82 [==============================] - 0s 2ms/step - loss: 0.2679 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "82/82 [==============================] - 0s 2ms/step - loss: 0.2079 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "82/82 [==============================] - 0s 3ms/step - loss: 0.1552 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "82/82 [==============================] - 0s 3ms/step - loss: 0.1105 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "82/82 [==============================] - 0s 2ms/step - loss: 0.0774 - acc: 1.0000\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "\n",
      "acc: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Utilisation de keras comme classifieur\n",
    "# mettre sigmoid comme fonction car binaire. Attention 1 seul neurone en sortie\n",
    "input_dim = len(data.columns) - 1\n",
    "model = Sequential()\n",
    "model.add(Dense(8, input_dim = input_dim , activation = 'relu'))\n",
    "model.add(Dense(10, activation = 'relu'))\n",
    "model.add(Dense(8, activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy' , optimizer = 'adam' , metrics = ['accuracy'] )\n",
    "\n",
    "model.fit(train_X, train_y, epochs = 10, batch_size = 2)\n",
    "\n",
    "scores = model.evaluate(test_X, test_y)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-13T18:33:04.723085Z",
     "start_time": "2020-02-13T18:33:04.681566Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Récupération seulement des bons classés\n",
    "X_good,y_good=get_goodXy (train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-13T18:33:04.796700Z",
     "start_time": "2020-02-13T18:33:04.725841Z"
    }
   },
   "outputs": [],
   "source": [
    "# Récupération des valeurs de tous les layers sauf le dernier\n",
    "result_layers=get_result_layers(model,X_good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-13T18:33:04.834457Z",
     "start_time": "2020-02-13T18:33:04.799432Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sauvegarde du fichier\n",
    "# structure :\n",
    "# 0/1 = valeur de la classe\n",
    "# chaque valeur de layer est entourée par un []\n",
    "save_result_layers(\"iris_8_10_8_tmp\",X_good,y_good,result_layers)\n",
    "# tri du fichier\n",
    "os.system ('sort iris_8_10_8_tmp > iris_8_10_8_.csv')\n",
    "# effacer le fichier intermédiaire\n",
    "os.system ('rm iris_8_10_8_tmp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Makemoons dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-13T18:33:04.856682Z",
     "start_time": "2020-02-13T18:33:04.836984Z"
    }
   },
   "outputs": [],
   "source": [
    "X, y = make_moons(n_samples=1000, noise=0.05, random_state=0)\n",
    "\n",
    "validation_size=0.6 #40% du jeu de données pour le test\n",
    "\n",
    "testsize= 1-validation_size\n",
    "seed=30\n",
    "# séparation jeu d'apprentissage et jeu de test\n",
    "train_X, test_X, train_y, test_y=model_selection.train_test_split(X, \n",
    "                                               y, \n",
    "                                               train_size=validation_size, \n",
    "                                               random_state=seed,\n",
    "                                               test_size=testsize)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-13T18:33:07.085494Z",
     "start_time": "2020-02-13T18:33:04.863442Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.6932 - acc: 0.5033\n",
      "Epoch 2/40\n",
      "600/600 [==============================] - 0s 75us/step - loss: 0.6931 - acc: 0.5033\n",
      "Epoch 3/40\n",
      "600/600 [==============================] - 0s 90us/step - loss: 0.6931 - acc: 0.5033\n",
      "Epoch 4/40\n",
      "600/600 [==============================] - 0s 85us/step - loss: 0.6931 - acc: 0.5033\n",
      "Epoch 5/40\n",
      "600/600 [==============================] - 0s 76us/step - loss: 0.6932 - acc: 0.5033\n",
      "Epoch 6/40\n",
      "600/600 [==============================] - 0s 80us/step - loss: 0.6931 - acc: 0.5033\n",
      "Epoch 7/40\n",
      "600/600 [==============================] - 0s 78us/step - loss: 0.6931 - acc: 0.5033\n",
      "Epoch 8/40\n",
      "600/600 [==============================] - 0s 82us/step - loss: 0.6931 - acc: 0.5033\n",
      "Epoch 9/40\n",
      "600/600 [==============================] - 0s 77us/step - loss: 0.6931 - acc: 0.5033\n",
      "Epoch 10/40\n",
      "600/600 [==============================] - 0s 77us/step - loss: 0.6931 - acc: 0.5033\n",
      "Epoch 11/40\n",
      "600/600 [==============================] - 0s 79us/step - loss: 0.6931 - acc: 0.5033\n",
      "Epoch 12/40\n",
      "600/600 [==============================] - 0s 78us/step - loss: 0.6931 - acc: 0.5033\n",
      "Epoch 13/40\n",
      "600/600 [==============================] - 0s 82us/step - loss: 0.6931 - acc: 0.5033\n",
      "Epoch 14/40\n",
      "600/600 [==============================] - 0s 82us/step - loss: 0.6931 - acc: 0.5033\n",
      "Epoch 15/40\n",
      "600/600 [==============================] - 0s 85us/step - loss: 0.6931 - acc: 0.5033\n",
      "Epoch 16/40\n",
      "600/600 [==============================] - 0s 83us/step - loss: 0.6931 - acc: 0.5033\n",
      "Epoch 17/40\n",
      "600/600 [==============================] - 0s 82us/step - loss: 0.6931 - acc: 0.5033\n",
      "Epoch 18/40\n",
      "600/600 [==============================] - 0s 85us/step - loss: 0.6931 - acc: 0.5033\n",
      "Epoch 19/40\n",
      "600/600 [==============================] - 0s 86us/step - loss: 0.6932 - acc: 0.5033\n",
      "Epoch 20/40\n",
      "600/600 [==============================] - 0s 81us/step - loss: 0.6932 - acc: 0.4833\n",
      "Epoch 21/40\n",
      "600/600 [==============================] - 0s 77us/step - loss: 0.6932 - acc: 0.4967\n",
      "Epoch 22/40\n",
      "600/600 [==============================] - 0s 80us/step - loss: 0.6932 - acc: 0.4933\n",
      "Epoch 23/40\n",
      "600/600 [==============================] - 0s 78us/step - loss: 0.6932 - acc: 0.5033\n",
      "Epoch 24/40\n",
      "600/600 [==============================] - 0s 75us/step - loss: 0.6931 - acc: 0.5033\n",
      "Epoch 25/40\n",
      "600/600 [==============================] - 0s 77us/step - loss: 0.6932 - acc: 0.5033\n",
      "Epoch 26/40\n",
      "600/600 [==============================] - 0s 77us/step - loss: 0.6932 - acc: 0.5033\n",
      "Epoch 27/40\n",
      "600/600 [==============================] - 0s 87us/step - loss: 0.6931 - acc: 0.5033\n",
      "Epoch 28/40\n",
      "600/600 [==============================] - 0s 78us/step - loss: 0.6931 - acc: 0.5033\n",
      "Epoch 29/40\n",
      "600/600 [==============================] - 0s 83us/step - loss: 0.6932 - acc: 0.5033\n",
      "Epoch 30/40\n",
      "600/600 [==============================] - 0s 80us/step - loss: 0.6931 - acc: 0.5033\n",
      "Epoch 31/40\n",
      "600/600 [==============================] - 0s 80us/step - loss: 0.6931 - acc: 0.5033\n",
      "Epoch 32/40\n",
      "600/600 [==============================] - 0s 76us/step - loss: 0.6932 - acc: 0.5033\n",
      "Epoch 33/40\n",
      "600/600 [==============================] - 0s 83us/step - loss: 0.6931 - acc: 0.5033\n",
      "Epoch 34/40\n",
      "600/600 [==============================] - 0s 71us/step - loss: 0.6931 - acc: 0.5033\n",
      "Epoch 35/40\n",
      "600/600 [==============================] - 0s 69us/step - loss: 0.6931 - acc: 0.5033\n",
      "Epoch 36/40\n",
      "600/600 [==============================] - 0s 58us/step - loss: 0.6931 - acc: 0.5033\n",
      "Epoch 37/40\n",
      "600/600 [==============================] - 0s 62us/step - loss: 0.6931 - acc: 0.5033\n",
      "Epoch 38/40\n",
      "600/600 [==============================] - 0s 63us/step - loss: 0.6931 - acc: 0.5033\n",
      "Epoch 39/40\n",
      "600/600 [==============================] - 0s 61us/step - loss: 0.6931 - acc: 0.5033\n",
      "Epoch 40/40\n",
      "600/600 [==============================] - 0s 68us/step - loss: 0.6931 - acc: 0.5033\n",
      "400/400 [==============================] - 0s 296us/step\n",
      "\n",
      "acc: 49.50%\n"
     ]
    }
   ],
   "source": [
    "# Utilisation de keras comme classifieur\n",
    "# mettre sigmoid comme fonction car binaire. Attention 1 seul neurone en sortie\n",
    "input_dim = 2\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(3, input_dim = input_dim , activation = 'relu'))\n",
    "model.add(Dense(10, activation = 'relu'))\n",
    "model.add(Dense(10, activation = 'relu'))\n",
    "model.add(Dense(3, activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy' , optimizer = 'adam' , metrics = ['accuracy'] )\n",
    "\n",
    "model.fit(train_X, train_y, epochs = 40, batch_size = 64)\n",
    "\n",
    "scores = model.evaluate(test_X, test_y)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-13T18:33:07.185481Z",
     "start_time": "2020-02-13T18:33:07.091570Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error prediction for X=[ 1.91258319 -0.02050477], Predicted=[0], Real=1\n",
      "error prediction for X=[ 0.46386062 -0.34983752], Predicted=[0], Real=1\n",
      "error prediction for X=[ 1.73868422 -0.23020397], Predicted=[0], Real=1\n",
      "error prediction for X=[ 1.69941636 -0.0902471 ], Predicted=[0], Real=1\n",
      "error prediction for X=[-0.02127692  0.43276319], Predicted=[0], Real=1\n",
      "error prediction for X=[ 1.4440003  -0.27070936], Predicted=[0], Real=1\n",
      "error prediction for X=[1.91498583 0.24413469], Predicted=[0], Real=1\n",
      "error prediction for X=[1.95940778 0.41269847], Predicted=[0], Real=1\n",
      "error prediction for X=[ 1.73674127 -0.18914707], Predicted=[0], Real=1\n",
      "error prediction for X=[ 0.90164201 -0.49598578], Predicted=[0], Real=1\n",
      "error prediction for X=[ 0.68827666 -0.42739017], Predicted=[0], Real=1\n",
      "error prediction for X=[1.96794954 0.56330206], Predicted=[0], Real=1\n",
      "error prediction for X=[1.87009386 0.02941778], Predicted=[0], Real=1\n",
      "error prediction for X=[ 1.78022302 -0.14096716], Predicted=[0], Real=1\n",
      "error prediction for X=[0.11524541 0.12244732], Predicted=[0], Real=1\n",
      "error prediction for X=[2.07635246 0.33088811], Predicted=[0], Real=1\n",
      "error prediction for X=[ 1.135602   -0.51268425], Predicted=[0], Real=1\n",
      "error prediction for X=[ 1.09553689 -0.53251758], Predicted=[0], Real=1\n",
      "error prediction for X=[ 0.51919238 -0.37559005], Predicted=[0], Real=1\n",
      "error prediction for X=[0.17611847 0.18963711], Predicted=[0], Real=1\n",
      "error prediction for X=[ 0.38780552 -0.18971303], Predicted=[0], Real=1\n",
      "error prediction for X=[ 0.32501026 -0.25696161], Predicted=[0], Real=1\n",
      "error prediction for X=[ 0.71915332 -0.36731277], Predicted=[0], Real=1\n",
      "error prediction for X=[ 0.2200827  -0.23048879], Predicted=[0], Real=1\n",
      "error prediction for X=[ 1.48879548 -0.4406033 ], Predicted=[0], Real=1\n",
      "error prediction for X=[1.91666907 0.44285449], Predicted=[0], Real=1\n",
      "error prediction for X=[1.93879127 0.5296443 ], Predicted=[0], Real=1\n",
      "error prediction for X=[2.0536965 0.1739818], Predicted=[0], Real=1\n",
      "error prediction for X=[ 0.5464397  -0.31064783], Predicted=[0], Real=1\n",
      "error prediction for X=[ 0.42734    -0.36450642], Predicted=[0], Real=1\n",
      "error prediction for X=[ 1.53063815 -0.2472427 ], Predicted=[0], Real=1\n",
      "error prediction for X=[ 0.90288315 -0.5192338 ], Predicted=[0], Real=1\n",
      "error prediction for X=[ 1.29132077 -0.37814796], Predicted=[0], Real=1\n",
      "error prediction for X=[1.83328716 0.17813355], Predicted=[0], Real=1\n",
      "error prediction for X=[ 1.1288101  -0.56591024], Predicted=[0], Real=1\n",
      "error prediction for X=[ 1.85628105 -0.01794053], Predicted=[0], Real=1\n",
      "error prediction for X=[ 0.18499276 -0.16173291], Predicted=[0], Real=1\n",
      "error prediction for X=[ 1.26086886 -0.53942369], Predicted=[0], Real=1\n",
      "error prediction for X=[ 0.59993686 -0.40543744], Predicted=[0], Real=1\n",
      "error prediction for X=[ 0.48129377 -0.29118442], Predicted=[0], Real=1\n",
      "error prediction for X=[ 0.90037246 -0.48694437], Predicted=[0], Real=1\n",
      "error prediction for X=[0.06989669 0.43533364], Predicted=[0], Real=1\n",
      "error prediction for X=[ 1.25785519 -0.55365078], Predicted=[0], Real=1\n",
      "error prediction for X=[ 1.32273106 -0.49671307], Predicted=[0], Real=1\n",
      "error prediction for X=[ 0.15336149 -0.18889865], Predicted=[0], Real=1\n",
      "error prediction for X=[ 0.81756295 -0.53295961], Predicted=[0], Real=1\n",
      "error prediction for X=[ 0.48473703 -0.41137324], Predicted=[0], Real=1\n",
      "error prediction for X=[0.06139013 0.13404682], Predicted=[0], Real=1\n",
      "error prediction for X=[-0.04510088  0.32899251], Predicted=[0], Real=1\n",
      "error prediction for X=[ 1.6689336  -0.25248665], Predicted=[0], Real=1\n",
      "error prediction for X=[0.02750255 0.15064462], Predicted=[0], Real=1\n",
      "error prediction for X=[0.11862021 0.1287095 ], Predicted=[0], Real=1\n",
      "error prediction for X=[ 0.18881427 -0.08373298], Predicted=[0], Real=1\n",
      "error prediction for X=[ 1.05578369 -0.45486009], Predicted=[0], Real=1\n",
      "error prediction for X=[-0.03374345  0.47690104], Predicted=[0], Real=1\n",
      "error prediction for X=[0.09024866 0.08255333], Predicted=[0], Real=1\n",
      "error prediction for X=[ 0.30576035 -0.16438857], Predicted=[0], Real=1\n",
      "error prediction for X=[ 1.61820869 -0.28159744], Predicted=[0], Real=1\n",
      "error prediction for X=[0.01403685 0.38685067], Predicted=[0], Real=1\n",
      "error prediction for X=[ 1.808835   -0.11838295], Predicted=[0], Real=1\n",
      "error prediction for X=[1.99119801 0.16375202], Predicted=[0], Real=1\n",
      "error prediction for X=[ 1.13009951 -0.47624438], Predicted=[0], Real=1\n",
      "error prediction for X=[1.95161887 0.27731515], Predicted=[0], Real=1\n",
      "error prediction for X=[2.02867835 0.33091113], Predicted=[0], Real=1\n",
      "error prediction for X=[ 1.83479346 -0.04041255], Predicted=[0], Real=1\n",
      "error prediction for X=[ 0.11805327 -0.00199044], Predicted=[0], Real=1\n",
      "error prediction for X=[ 1.83459686 -0.13982839], Predicted=[0], Real=1\n",
      "error prediction for X=[1.8920658  0.07209668], Predicted=[0], Real=1\n",
      "error prediction for X=[ 1.17029386 -0.48526253], Predicted=[0], Real=1\n",
      "error prediction for X=[ 1.19336656 -0.52081076], Predicted=[0], Real=1\n",
      "error prediction for X=[0.0377648  0.26994513], Predicted=[0], Real=1\n",
      "error prediction for X=[1.81760764e+00 6.80679015e-04], Predicted=[0], Real=1\n",
      "error prediction for X=[ 1.84962878 -0.18284849], Predicted=[0], Real=1\n",
      "error prediction for X=[ 0.29127212 -0.20372863], Predicted=[0], Real=1\n",
      "error prediction for X=[ 0.38807878 -0.29000131], Predicted=[0], Real=1\n",
      "error prediction for X=[ 0.11741305 -0.05865582], Predicted=[0], Real=1\n",
      "error prediction for X=[0.13227256 0.07772106], Predicted=[0], Real=1\n",
      "error prediction for X=[0.00744165 0.41895263], Predicted=[0], Real=1\n",
      "error prediction for X=[0.04237701 0.08906862], Predicted=[0], Real=1\n",
      "error prediction for X=[ 0.95472675 -0.55608022], Predicted=[0], Real=1\n",
      "error prediction for X=[ 0.49449796 -0.38802467], Predicted=[0], Real=1\n",
      "error prediction for X=[1.92805053 0.32890208], Predicted=[0], Real=1\n",
      "error prediction for X=[ 0.54853342 -0.41863755], Predicted=[0], Real=1\n",
      "error prediction for X=[ 1.80900627 -0.16760177], Predicted=[0], Real=1\n",
      "error prediction for X=[ 0.19475533 -0.13208272], Predicted=[0], Real=1\n",
      "error prediction for X=[ 0.87109571 -0.47480286], Predicted=[0], Real=1\n",
      "error prediction for X=[ 1.26475797 -0.53119673], Predicted=[0], Real=1\n",
      "error prediction for X=[1.9054882  0.26538754], Predicted=[0], Real=1\n",
      "error prediction for X=[ 1.03381335 -0.50255117], Predicted=[0], Real=1\n",
      "error prediction for X=[ 1.36315633 -0.31310247], Predicted=[0], Real=1\n",
      "error prediction for X=[ 0.13883091 -0.01110231], Predicted=[0], Real=1\n",
      "error prediction for X=[ 0.8910353  -0.50777893], Predicted=[0], Real=1\n",
      "error prediction for X=[ 1.50755676 -0.32420741], Predicted=[0], Real=1\n",
      "error prediction for X=[0.10374309 0.01069576], Predicted=[0], Real=1\n",
      "error prediction for X=[ 0.94206153 -0.50136882], Predicted=[0], Real=1\n",
      "error prediction for X=[ 0.66760773 -0.49638282], Predicted=[0], Real=1\n",
      "error prediction for X=[ 1.13847021 -0.49784014], Predicted=[0], Real=1\n",
      "error prediction for X=[ 0.65607    -0.39038739], Predicted=[0], Real=1\n",
      "error prediction for X=[ 0.3437557  -0.27419829], Predicted=[0], Real=1\n",
      "error prediction for X=[ 1.7026491  -0.17591201], Predicted=[0], Real=1\n",
      "error prediction for X=[ 0.17375645 -0.10042012], Predicted=[0], Real=1\n",
      "error prediction for X=[ 0.17683409 -0.16157378], Predicted=[0], Real=1\n",
      "error prediction for X=[1.99745491 0.1434324 ], Predicted=[0], Real=1\n",
      "error prediction for X=[-0.0036593   0.49972241], Predicted=[0], Real=1\n",
      "error prediction for X=[ 0.85940516 -0.42257249], Predicted=[0], Real=1\n",
      "error prediction for X=[2.03399247 0.29051853], Predicted=[0], Real=1\n",
      "error prediction for X=[ 1.25587467 -0.60522529], Predicted=[0], Real=1\n",
      "error prediction for X=[ 1.83226952 -0.0432984 ], Predicted=[0], Real=1\n",
      "error prediction for X=[ 1.5376082  -0.39171211], Predicted=[0], Real=1\n",
      "error prediction for X=[1.88368618 0.0307736 ], Predicted=[0], Real=1\n",
      "error prediction for X=[ 0.99791276 -0.51714221], Predicted=[0], Real=1\n",
      "error prediction for X=[ 0.12441834 -0.01665721], Predicted=[0], Real=1\n",
      "error prediction for X=[ 1.33402957 -0.42155616], Predicted=[0], Real=1\n",
      "error prediction for X=[ 0.46434451 -0.30422757], Predicted=[0], Real=1\n",
      "error prediction for X=[ 0.88101454 -0.59801987], Predicted=[0], Real=1\n",
      "error prediction for X=[ 1.11123306 -0.51426632], Predicted=[0], Real=1\n",
      "error prediction for X=[ 1.64470206 -0.34463258], Predicted=[0], Real=1\n",
      "error prediction for X=[ 1.48757135 -0.41830148], Predicted=[0], Real=1\n",
      "error prediction for X=[ 0.88685155 -0.50663316], Predicted=[0], Real=1\n",
      "error prediction for X=[ 0.28565352 -0.23892753], Predicted=[0], Real=1\n",
      "error prediction for X=[ 1.59731575 -0.24383666], Predicted=[0], Real=1\n",
      "error prediction for X=[0.09757054 0.1183474 ], Predicted=[0], Real=1\n",
      "error prediction for X=[-0.01716732  0.43214231], Predicted=[0], Real=1\n",
      "error prediction for X=[ 1.89020428 -0.01246338], Predicted=[0], Real=1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error prediction for X=[ 1.4432624 -0.403265 ], Predicted=[0], Real=1\n",
      "error prediction for X=[1.95458913 0.12701995], Predicted=[0], Real=1\n",
      "error prediction for X=[ 0.47224436 -0.28129086], Predicted=[0], Real=1\n",
      "error prediction for X=[1.92971771 0.16493063], Predicted=[0], Real=1\n",
      "error prediction for X=[0.06092146 0.14241808], Predicted=[0], Real=1\n",
      "error prediction for X=[ 1.63401677 -0.33225386], Predicted=[0], Real=1\n",
      "error prediction for X=[ 1.6782009  -0.20198687], Predicted=[0], Real=1\n",
      "error prediction for X=[ 1.53671798 -0.38015053], Predicted=[0], Real=1\n",
      "error prediction for X=[ 1.47391568 -0.33877942], Predicted=[0], Real=1\n",
      "error prediction for X=[ 1.78819227 -0.12973943], Predicted=[0], Real=1\n",
      "error prediction for X=[ 1.09174793 -0.46306249], Predicted=[0], Real=1\n",
      "error prediction for X=[1.94401642 0.34854826], Predicted=[0], Real=1\n",
      "error prediction for X=[ 0.27955131 -0.31834945], Predicted=[0], Real=1\n",
      "error prediction for X=[-0.01289267  0.27685662], Predicted=[0], Real=1\n",
      "error prediction for X=[ 1.44766818 -0.46973359], Predicted=[0], Real=1\n",
      "error prediction for X=[ 1.06607797 -0.48057873], Predicted=[0], Real=1\n",
      "error prediction for X=[2.07885821 0.43001161], Predicted=[0], Real=1\n",
      "error prediction for X=[1.97601532 0.47957386], Predicted=[0], Real=1\n",
      "error prediction for X=[ 1.77758256 -0.02040948], Predicted=[0], Real=1\n",
      "error prediction for X=[ 1.85588292 -0.03898709], Predicted=[0], Real=1\n",
      "error prediction for X=[2.005666   0.32717757], Predicted=[0], Real=1\n",
      "error prediction for X=[1.96469773 0.33729174], Predicted=[0], Real=1\n",
      "error prediction for X=[1.93008419 0.27785691], Predicted=[0], Real=1\n",
      "error prediction for X=[0.16989287 0.22748211], Predicted=[0], Real=1\n",
      "error prediction for X=[ 0.90213588 -0.54317269], Predicted=[0], Real=1\n",
      "error prediction for X=[0.08591108 0.45574555], Predicted=[0], Real=1\n",
      "error prediction for X=[ 0.08452708 -0.01089087], Predicted=[0], Real=1\n",
      "error prediction for X=[ 1.46433731 -0.41011996], Predicted=[0], Real=1\n",
      "error prediction for X=[ 1.61144406 -0.23504401], Predicted=[0], Real=1\n",
      "error prediction for X=[ 1.20274515 -0.52357541], Predicted=[0], Real=1\n",
      "error prediction for X=[ 0.97456971 -0.41610216], Predicted=[0], Real=1\n",
      "error prediction for X=[-0.0528536   0.35986457], Predicted=[0], Real=1\n",
      "error prediction for X=[2.01994184 0.20373451], Predicted=[0], Real=1\n",
      "error prediction for X=[ 1.8655233  -0.04722777], Predicted=[0], Real=1\n",
      "error prediction for X=[ 1.52276609 -0.38396181], Predicted=[0], Real=1\n",
      "error prediction for X=[ 0.46356562 -0.4414356 ], Predicted=[0], Real=1\n",
      "error prediction for X=[ 1.80577578 -0.07487215], Predicted=[0], Real=1\n",
      "error prediction for X=[ 1.64632579 -0.29753734], Predicted=[0], Real=1\n",
      "error prediction for X=[ 0.69330874 -0.43853174], Predicted=[0], Real=1\n",
      "error prediction for X=[ 0.7215666  -0.41903614], Predicted=[0], Real=1\n",
      "error prediction for X=[ 0.66726265 -0.48091323], Predicted=[0], Real=1\n",
      "error prediction for X=[ 0.22906785 -0.18583156], Predicted=[0], Real=1\n",
      "error prediction for X=[1.97167213 0.31004711], Predicted=[0], Real=1\n",
      "error prediction for X=[-0.04805998  0.40732407], Predicted=[0], Real=1\n",
      "error prediction for X=[ 0.46919065 -0.46074985], Predicted=[0], Real=1\n",
      "error prediction for X=[1.93958441 0.16135041], Predicted=[0], Real=1\n",
      "error prediction for X=[ 1.29321621 -0.42330528], Predicted=[0], Real=1\n",
      "error prediction for X=[ 1.76602056 -0.20598016], Predicted=[0], Real=1\n",
      "error prediction for X=[ 0.45876436 -0.30792828], Predicted=[0], Real=1\n",
      "error prediction for X=[ 1.57881155 -0.29960622], Predicted=[0], Real=1\n",
      "error prediction for X=[ 1.52178652 -0.41290836], Predicted=[0], Real=1\n",
      "error prediction for X=[ 0.96706282 -0.53911939], Predicted=[0], Real=1\n",
      "error prediction for X=[ 1.4063002  -0.52941502], Predicted=[0], Real=1\n",
      "error prediction for X=[1.96953895 0.36005521], Predicted=[0], Real=1\n",
      "error prediction for X=[0.21761688 0.02923433], Predicted=[0], Real=1\n",
      "error prediction for X=[ 0.96176346 -0.49099002], Predicted=[0], Real=1\n",
      "error prediction for X=[ 0.80528575 -0.49915901], Predicted=[0], Real=1\n",
      "error prediction for X=[ 1.28440029 -0.45268419], Predicted=[0], Real=1\n",
      "error prediction for X=[ 1.23998248 -0.40447297], Predicted=[0], Real=1\n",
      "error prediction for X=[ 1.77932108 -0.24450853], Predicted=[0], Real=1\n",
      "error prediction for X=[1.98966625 0.07826262], Predicted=[0], Real=1\n",
      "error prediction for X=[ 0.85998609 -0.44544471], Predicted=[0], Real=1\n",
      "error prediction for X=[ 1.63073313 -0.42202517], Predicted=[0], Real=1\n",
      "error prediction for X=[ 1.02707331 -0.43965571], Predicted=[0], Real=1\n",
      "error prediction for X=[-0.01698712  0.4447934 ], Predicted=[0], Real=1\n",
      "error prediction for X=[ 1.69155311 -0.21475114], Predicted=[0], Real=1\n",
      "error prediction for X=[ 0.50484202 -0.3910431 ], Predicted=[0], Real=1\n",
      "error prediction for X=[ 0.86471533 -0.46391986], Predicted=[0], Real=1\n",
      "error prediction for X=[1.91373233 0.16091458], Predicted=[0], Real=1\n",
      "error prediction for X=[-0.02811529  0.33395463], Predicted=[0], Real=1\n",
      "error prediction for X=[ 0.19569379 -0.09973222], Predicted=[0], Real=1\n",
      "error prediction for X=[ 1.35843345 -0.53343881], Predicted=[0], Real=1\n",
      "error prediction for X=[ 1.94738957 -0.05969297], Predicted=[0], Real=1\n",
      "error prediction for X=[ 0.4953548  -0.47910581], Predicted=[0], Real=1\n",
      "error prediction for X=[1.94854454 0.11839257], Predicted=[0], Real=1\n",
      "error prediction for X=[0.00585844 0.43348388], Predicted=[0], Real=1\n",
      "error prediction for X=[1.93264128 0.33661435], Predicted=[0], Real=1\n",
      "error prediction for X=[ 1.18054666 -0.47366596], Predicted=[0], Real=1\n",
      "error prediction for X=[ 0.42300978 -0.35737938], Predicted=[0], Real=1\n",
      "error prediction for X=[ 0.63019927 -0.45132527], Predicted=[0], Real=1\n",
      "error prediction for X=[ 1.66918118 -0.24797055], Predicted=[0], Real=1\n",
      "error prediction for X=[ 1.59109852 -0.33768534], Predicted=[0], Real=1\n",
      "error prediction for X=[ 0.68117831 -0.45676867], Predicted=[0], Real=1\n",
      "error prediction for X=[ 1.70472609 -0.16918493], Predicted=[0], Real=1\n",
      "error prediction for X=[-0.01173956  0.35444598], Predicted=[0], Real=1\n",
      "error prediction for X=[1.93438349 0.12810749], Predicted=[0], Real=1\n",
      "error prediction for X=[ 0.38848462 -0.37217799], Predicted=[0], Real=1\n",
      "error prediction for X=[ 0.55474148 -0.44164809], Predicted=[0], Real=1\n",
      "error prediction for X=[ 1.26620427 -0.50839702], Predicted=[0], Real=1\n",
      "error prediction for X=[ 1.50915176 -0.32318443], Predicted=[0], Real=1\n",
      "error prediction for X=[ 0.19565691 -0.03429648], Predicted=[0], Real=1\n",
      "error prediction for X=[ 0.90577562 -0.45638584], Predicted=[0], Real=1\n",
      "error prediction for X=[ 1.14850565 -0.47164386], Predicted=[0], Real=1\n",
      "error prediction for X=[0.0192657  0.45696303], Predicted=[0], Real=1\n",
      "error prediction for X=[ 0.20901599 -0.16826225], Predicted=[0], Real=1\n",
      "error prediction for X=[ 1.93644344 -0.05906555], Predicted=[0], Real=1\n",
      "error prediction for X=[2.07098592 0.3483436 ], Predicted=[0], Real=1\n",
      "error prediction for X=[ 0.14843221 -0.06469251], Predicted=[0], Real=1\n",
      "error prediction for X=[ 0.71572367 -0.47050442], Predicted=[0], Real=1\n",
      "error prediction for X=[1.9091975  0.37992637], Predicted=[0], Real=1\n",
      "error prediction for X=[0.1252038  0.23540698], Predicted=[0], Real=1\n",
      "error prediction for X=[ 0.26814837 -0.18675925], Predicted=[0], Real=1\n",
      "error prediction for X=[ 1.57759298 -0.32582929], Predicted=[0], Real=1\n",
      "error prediction for X=[ 0.80342103 -0.45531432], Predicted=[0], Real=1\n",
      "error prediction for X=[0.00702268 0.32234294], Predicted=[0], Real=1\n",
      "error prediction for X=[ 0.82806138 -0.48569266], Predicted=[0], Real=1\n",
      "error prediction for X=[ 0.85637678 -0.45604028], Predicted=[0], Real=1\n",
      "error prediction for X=[ 1.50881658 -0.43147172], Predicted=[0], Real=1\n",
      "error prediction for X=[0.07344505 0.18232956], Predicted=[0], Real=1\n",
      "error prediction for X=[ 0.20810684 -0.0755112 ], Predicted=[0], Real=1\n",
      "error prediction for X=[ 1.49039351 -0.3718049 ], Predicted=[0], Real=1\n",
      "error prediction for X=[0.11069982 0.15882099], Predicted=[0], Real=1\n",
      "error prediction for X=[ 1.47294796 -0.34159254], Predicted=[0], Real=1\n",
      "error prediction for X=[1.94907949 0.34066257], Predicted=[0], Real=1\n",
      "error prediction for X=[-0.00240739  0.51808083], Predicted=[0], Real=1\n",
      "error prediction for X=[0.01899996 0.11208458], Predicted=[0], Real=1\n",
      "error prediction for X=[ 0.70751638 -0.5126737 ], Predicted=[0], Real=1\n",
      "error prediction for X=[ 0.43251853 -0.42715108], Predicted=[0], Real=1\n",
      "error prediction for X=[0.02765452 0.29013086], Predicted=[0], Real=1\n",
      "error prediction for X=[0.0779506  0.13147202], Predicted=[0], Real=1\n",
      "error prediction for X=[ 1.7259367  -0.22726401], Predicted=[0], Real=1\n",
      "error prediction for X=[0.12857102 0.00040207], Predicted=[0], Real=1\n",
      "error prediction for X=[0.05162724 0.19915229], Predicted=[0], Real=1\n",
      "error prediction for X=[ 0.31489108 -0.07876427], Predicted=[0], Real=1\n",
      "error prediction for X=[ 0.22901239 -0.07911408], Predicted=[0], Real=1\n",
      "error prediction for X=[0.04125468 0.34876154], Predicted=[0], Real=1\n",
      "error prediction for X=[ 1.17761069 -0.43477062], Predicted=[0], Real=1\n",
      "error prediction for X=[ 1.78354815 -0.14669598], Predicted=[0], Real=1\n",
      "error prediction for X=[ 1.34766713 -0.45755917], Predicted=[0], Real=1\n",
      "error prediction for X=[ 1.50123378 -0.27351255], Predicted=[0], Real=1\n",
      "error prediction for X=[ 0.28721227 -0.19330967], Predicted=[0], Real=1\n",
      "error prediction for X=[ 1.84422635 -0.01443755], Predicted=[0], Real=1\n",
      "error prediction for X=[ 1.37649074 -0.42319433], Predicted=[0], Real=1\n",
      "error prediction for X=[1.98244635 0.15221991], Predicted=[0], Real=1\n",
      "error prediction for X=[ 0.31833622 -0.16590584], Predicted=[0], Real=1\n",
      "error prediction for X=[0.09133842 0.33478158], Predicted=[0], Real=1\n",
      "error prediction for X=[ 1.30878184 -0.437787  ], Predicted=[0], Real=1\n",
      "error prediction for X=[ 1.58741701 -0.31529806], Predicted=[0], Real=1\n",
      "error prediction for X=[ 0.63863698 -0.35967717], Predicted=[0], Real=1\n",
      "error prediction for X=[ 0.87494974 -0.59189851], Predicted=[0], Real=1\n",
      "error prediction for X=[0.12549126 0.19127898], Predicted=[0], Real=1\n",
      "error prediction for X=[1.93065477 0.37767182], Predicted=[0], Real=1\n",
      "error prediction for X=[ 0.96526961 -0.53416762], Predicted=[0], Real=1\n",
      "error prediction for X=[1.91769554 0.41925661], Predicted=[0], Real=1\n",
      "error prediction for X=[ 0.12138682 -0.02521479], Predicted=[0], Real=1\n",
      "error prediction for X=[ 0.80239652 -0.48790254], Predicted=[0], Real=1\n",
      "error prediction for X=[ 0.09303963 -0.04400871], Predicted=[0], Real=1\n",
      "error prediction for X=[ 1.89291288 -0.0472769 ], Predicted=[0], Real=1\n",
      "error prediction for X=[ 0.83757676 -0.43544021], Predicted=[0], Real=1\n",
      "error prediction for X=[ 0.15057505 -0.03777511], Predicted=[0], Real=1\n",
      "error prediction for X=[ 0.72949175 -0.53536269], Predicted=[0], Real=1\n",
      "error prediction for X=[ 1.33579314 -0.41180636], Predicted=[0], Real=1\n",
      "error prediction for X=[0.04294959 0.29560264], Predicted=[0], Real=1\n",
      "error prediction for X=[ 1.40472022 -0.40150328], Predicted=[0], Real=1\n",
      "error prediction for X=[ 1.49791658 -0.46177768], Predicted=[0], Real=1\n",
      "error prediction for X=[ 1.5690433  -0.26811405], Predicted=[0], Real=1\n",
      "error prediction for X=[ 0.86795013 -0.51245969], Predicted=[0], Real=1\n",
      "error prediction for X=[ 1.79582737 -0.16138616], Predicted=[0], Real=1\n",
      "error prediction for X=[ 1.37031857 -0.43950794], Predicted=[0], Real=1\n",
      "error prediction for X=[0.06379536 0.24755759], Predicted=[0], Real=1\n",
      "error prediction for X=[ 0.66108069 -0.46113978], Predicted=[0], Real=1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error prediction for X=[ 1.67568975 -0.22968208], Predicted=[0], Real=1\n",
      "error prediction for X=[ 0.8406083  -0.57464379], Predicted=[0], Real=1\n",
      "error prediction for X=[ 0.32515039 -0.32838537], Predicted=[0], Real=1\n",
      "error prediction for X=[ 1.38784935 -0.41236273], Predicted=[0], Real=1\n",
      "error prediction for X=[1.98799225 0.414105  ], Predicted=[0], Real=1\n",
      "error prediction for X=[ 0.4119216  -0.24592777], Predicted=[0], Real=1\n",
      "error prediction for X=[ 0.40120659 -0.23351411], Predicted=[0], Real=1\n",
      "error prediction for X=[2.01108954 0.44227458], Predicted=[0], Real=1\n",
      "error prediction for X=[ 0.85102061 -0.50589137], Predicted=[0], Real=1\n",
      "error prediction for X=[ 1.63320058 -0.22160531], Predicted=[0], Real=1\n",
      "error prediction for X=[ 0.34888228 -0.18793122], Predicted=[0], Real=1\n",
      "error prediction for X=[ 1.40984549 -0.48242883], Predicted=[0], Real=1\n",
      "error prediction for X=[ 0.18790158 -0.12805293], Predicted=[0], Real=1\n"
     ]
    }
   ],
   "source": [
    "# Récupération seulement des bons classés\n",
    "X_good,y_good=get_goodXy (train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-13T18:33:07.364113Z",
     "start_time": "2020-02-13T18:33:07.190335Z"
    }
   },
   "outputs": [],
   "source": [
    "# Récupération des valeurs de tous les layers sauf le dernier\n",
    "result_layers=get_result_layers(model,X_good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-13T18:33:07.435041Z",
     "start_time": "2020-02-13T18:33:07.366852Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sauvegarde du fichier\n",
    "# structure :\n",
    "# 0/1 = valeur de la classe\n",
    "# chaque valeur de layer est entourée par une étoile *\n",
    "save_result_layers(\"makemoons_3_10_10_3_tmp\",X_good,y_good,result_layers)\n",
    "# tri du fichier\n",
    "os.system ('sort makemoons_3_10_10_3_tmp > makemoons_3_10_10_3_.csv')\n",
    "# effacer le fichier intermédiaire\n",
    "os.system ('rm makemoons_3_10_10_3_tmp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mnist dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-13T18:33:07.706098Z",
     "start_time": "2020-02-13T18:33:07.438541Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train_sample=X_train[0:100]\n",
    "y_train_sample=y_train[0:100]\n",
    "\n",
    "X_train=X_train_sample\n",
    "y_train=y_train_sample\n",
    "X_train = X_train.reshape(100, 784)\n",
    "X_train = X_train.astype('float32')\n",
    "\n",
    "X_train /= 255\n",
    "\n",
    "\n",
    "\n",
    "X_01=[]\n",
    "y_01=[]\n",
    "nb_X=0\n",
    "for i in range(X_train.shape[0]):\n",
    "    if (y_train[i]==0 or y_train[i]==1):\n",
    "        \n",
    "        nb_X+=1\n",
    "        X_01.append(X_train[i])\n",
    "        y_01.append(y_train[i])\n",
    "\n",
    "       \n",
    "train_X=np.asarray(X_01)\n",
    "\n",
    "train_y=y_01\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "train_y=encoder.fit_transform(train_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-13T18:33:09.053307Z",
     "start_time": "2020-02-13T18:33:07.709000Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "27/27 [==============================] - 1s 22ms/step - loss: 0.7341 - acc: 0.3704\n",
      "Epoch 2/40\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.4064 - acc: 0.8519\n",
      "Epoch 3/40\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.2594 - acc: 1.0000\n",
      "Epoch 4/40\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1619 - acc: 1.0000\n",
      "Epoch 5/40\n",
      "27/27 [==============================] - 0s 255us/step - loss: 0.1022 - acc: 1.0000\n",
      "Epoch 6/40\n",
      "27/27 [==============================] - 0s 632us/step - loss: 0.0631 - acc: 1.0000\n",
      "Epoch 7/40\n",
      "27/27 [==============================] - 0s 371us/step - loss: 0.0406 - acc: 1.0000\n",
      "Epoch 8/40\n",
      "27/27 [==============================] - 0s 680us/step - loss: 0.0269 - acc: 1.0000\n",
      "Epoch 9/40\n",
      "27/27 [==============================] - 0s 567us/step - loss: 0.0186 - acc: 1.0000\n",
      "Epoch 10/40\n",
      "27/27 [==============================] - 0s 534us/step - loss: 0.0135 - acc: 1.0000\n",
      "Epoch 11/40\n",
      "27/27 [==============================] - 0s 679us/step - loss: 0.0101 - acc: 1.0000\n",
      "Epoch 12/40\n",
      "27/27 [==============================] - 0s 372us/step - loss: 0.0077 - acc: 1.0000\n",
      "Epoch 13/40\n",
      "27/27 [==============================] - 0s 318us/step - loss: 0.0060 - acc: 1.0000\n",
      "Epoch 14/40\n",
      "27/27 [==============================] - 0s 413us/step - loss: 0.0048 - acc: 1.0000\n",
      "Epoch 15/40\n",
      "27/27 [==============================] - 0s 268us/step - loss: 0.0038 - acc: 1.0000\n",
      "Epoch 16/40\n",
      "27/27 [==============================] - 0s 201us/step - loss: 0.0030 - acc: 1.0000\n",
      "Epoch 17/40\n",
      "27/27 [==============================] - 0s 243us/step - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 18/40\n",
      "27/27 [==============================] - 0s 440us/step - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 19/40\n",
      "27/27 [==============================] - 0s 661us/step - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 20/40\n",
      "27/27 [==============================] - 0s 445us/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 21/40\n",
      "27/27 [==============================] - 0s 304us/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 22/40\n",
      "27/27 [==============================] - 0s 327us/step - loss: 9.4200e-04 - acc: 1.0000\n",
      "Epoch 23/40\n",
      "27/27 [==============================] - 0s 218us/step - loss: 8.0517e-04 - acc: 1.0000\n",
      "Epoch 24/40\n",
      "27/27 [==============================] - 0s 320us/step - loss: 6.9646e-04 - acc: 1.0000\n",
      "Epoch 25/40\n",
      "27/27 [==============================] - 0s 420us/step - loss: 6.0926e-04 - acc: 1.0000\n",
      "Epoch 26/40\n",
      "27/27 [==============================] - 0s 265us/step - loss: 5.3830e-04 - acc: 1.0000\n",
      "Epoch 27/40\n",
      "27/27 [==============================] - 0s 424us/step - loss: 4.8019e-04 - acc: 1.0000\n",
      "Epoch 28/40\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 4.3231e-04 - acc: 1.0000\n",
      "Epoch 29/40\n",
      "27/27 [==============================] - 0s 696us/step - loss: 3.9255e-04 - acc: 1.0000\n",
      "Epoch 30/40\n",
      "27/27 [==============================] - 0s 521us/step - loss: 3.5914e-04 - acc: 1.0000\n",
      "Epoch 31/40\n",
      "27/27 [==============================] - 0s 463us/step - loss: 3.3092e-04 - acc: 1.0000\n",
      "Epoch 32/40\n",
      "27/27 [==============================] - 0s 318us/step - loss: 3.0690e-04 - acc: 1.0000\n",
      "Epoch 33/40\n",
      "27/27 [==============================] - 0s 448us/step - loss: 2.8632e-04 - acc: 1.0000\n",
      "Epoch 34/40\n",
      "27/27 [==============================] - 0s 362us/step - loss: 2.6854e-04 - acc: 1.0000\n",
      "Epoch 35/40\n",
      "27/27 [==============================] - 0s 379us/step - loss: 2.5314e-04 - acc: 1.0000\n",
      "Epoch 36/40\n",
      "27/27 [==============================] - 0s 584us/step - loss: 2.3968e-04 - acc: 1.0000\n",
      "Epoch 37/40\n",
      "27/27 [==============================] - 0s 663us/step - loss: 2.2787e-04 - acc: 1.0000\n",
      "Epoch 38/40\n",
      "27/27 [==============================] - 0s 443us/step - loss: 2.1748e-04 - acc: 1.0000\n",
      "Epoch 39/40\n",
      "27/27 [==============================] - 0s 712us/step - loss: 2.0833e-04 - acc: 1.0000\n",
      "Epoch 40/40\n",
      "27/27 [==============================] - 0s 333us/step - loss: 2.0020e-04 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f94280fe9e8>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dim = 784\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, input_dim = input_dim , activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy' , optimizer = 'adam' , metrics = ['accuracy'] )\n",
    "\n",
    "model.fit(train_X, train_y, epochs = 40, batch_size = 32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-13T18:33:09.146427Z",
     "start_time": "2020-02-13T18:33:09.056929Z"
    }
   },
   "outputs": [],
   "source": [
    "X_good,y_good=get_goodXy (train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-13T18:33:09.236211Z",
     "start_time": "2020-02-13T18:33:09.149111Z"
    }
   },
   "outputs": [],
   "source": [
    "# Récupération des valeurs de tous les layers sauf le dernier\n",
    "result_layers=get_result_layers(model,X_good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-13T18:33:09.301419Z",
     "start_time": "2020-02-13T18:33:09.239056Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sauvegarde du fichier\n",
    "# structure :\n",
    "# 0/1 = valeur de la classe\n",
    "# chaque valeur de layer est entourée par une étoile *\n",
    "save_result_layers(\"mnist_512_tmp\",X_good,y_good,result_layers)\n",
    "# tri du fichier\n",
    "os.system ('sort mnist_512_tmp > mnist_512_.csv')\n",
    "# effacer le fichier intermédiaire\n",
    "os.system ('rm mnist_512_tmp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-13T18:33:09.461149Z",
     "start_time": "2020-02-13T18:33:09.307419Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_directory_layers_from_csv(filename):\n",
    "    tokens=filename.split(\"_\")\n",
    "    df = pd.read_csv(filename, sep = ',', header = None) \n",
    "\n",
    "    \n",
    "    # creation d'un répertoire pour sauver tous les fichiers\n",
    "    repertoire=filename[0:-4]\n",
    "    os.makedirs(repertoire, exist_ok=True)\n",
    "    string = repertoire+'/'+tokens[0]+'_'\n",
    "    f=[]\n",
    "    filenames=[]\n",
    "    for nb_tokens in range (1,len(tokens)-1):\n",
    "        name_file=string+'l'+str(nb_tokens)+'_'+tokens[nb_tokens]+'.csv'\n",
    "        f.append(open(name_file, \"w\"))\n",
    "        filenames.append(name_file)\n",
    "        \n",
    "        \n",
    "    # sauvegarde du dataframe dans une chaîne de caracteres\n",
    "    ch = df.to_string(header=False,\n",
    "                  index=False,\n",
    "                  index_names=False).split('\\n')\n",
    "    vals = [','.join(ele.split()) for ele in ch]\n",
    "    \n",
    "    # sauvegarde dans des fichiers spécifiques par layer\n",
    "    token_layer=[]\n",
    "    token_exemples=[]\n",
    "    for nb_exemples in range (len(vals)):\n",
    "        deb=str(df[0][nb_exemples])+','\n",
    "        # 1 ligne correspond à une chaine\n",
    "        s=vals[nb_exemples]\n",
    "        listoftokens=re.findall(r'<b>,(.+?),</b>', s)\n",
    "        nb_layers=len(listoftokens)\n",
    "        \n",
    "        for nb_token in range (nb_layers):\n",
    "            save_token=''\n",
    "            save_token=deb+str(listoftokens[nb_token])+'\\n'\n",
    "            \n",
    "            f[nb_token].write(save_token)\n",
    "\n",
    "    # sauvegarde d'un fichier qui contient tous les layers en une fois\n",
    "    # récupération des données pour enlever les <b> et </b>\n",
    "    df_all=pd.DataFrame()\n",
    "    myindex=0\n",
    "    for nb_columns in range(df.shape[1]):\n",
    "        df[nb_columns]=df[nb_columns].astype(str)\n",
    "        if (df[nb_columns]!='<b>').all() and (df[nb_columns]!='</b>').all():\n",
    "            df_all[myindex]=df[nb_columns]\n",
    "            myindex+=1\n",
    "\n",
    "    # construction du nom du fichier de sauvegarde\n",
    "    string = repertoire+'/'+tokens[0]+'_'\n",
    "    for nb_tokens in range (1,len(tokens)-1):\n",
    "        string+='l'+str(nb_tokens)+'_'+tokens[nb_tokens]+'_'\n",
    "    string+='.csv'       \n",
    "    # sauvegarde en .csv\n",
    "    df_all.to_csv(string, sep=',', encoding='utf-8',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-13T18:33:10.241840Z",
     "start_time": "2020-02-13T18:33:09.463887Z"
    }
   },
   "outputs": [],
   "source": [
    "#Create a directory with a specific file for all the layers\n",
    "filename=\"iris_8_10_8_.csv\"    \n",
    "get_directory_layers_from_csv(filename)    \n",
    "\n",
    "filename='makemoons_3_10_10_3_.csv'\n",
    "get_directory_layers_from_csv(filename) \n",
    "\n",
    "filename='mnist_512_.csv'\n",
    "get_directory_layers_from_csv(filename) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traitement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0  1  2  3  4  5  6  7  8\n",
      "0  0  0  0  0  0  0  2  0  0\n",
      "1  0  0  0  0  0  0  2  0  0\n",
      "2  0  0  0  0  0  0  2  0  0\n",
      "3  0  0  0  0  0  0  2  0  0\n",
      "4  0  0  0  0  0  0  2  0  0\n",
      "    0  1  2  3  4  5  6  7  8\n",
      "77  1  0  0  0  0  1  4  0  1\n",
      "78  1  0  0  0  0  1  4  0  1\n",
      "79  1  0  0  0  0  1  4  0  2\n",
      "80  1  0  0  0  0  1  4  0  2\n",
      "81  1  0  0  0  0  1  4  0  1\n",
      "5\n",
      "['2.021001,0.490179', '1.678201,-0.201987', '-0.282245,0.858785', '-0.021440,0.176281', '0.504842,-0.391043', '1.969539,0.360055', '0.956596,0.253665', '0.094879,0.983378', '-0.441660,0.872034', '0.707516,-0.512674', '-1.052250,0.047481', '0.073445,0.182330', '1.320594,-0.509063', '0.082926,0.916587', '0.103743,0.010696', '0.894168,0.341012', '1.817608,0.000681', '0.475219,0.819541', '1.027841,0.159873', '0.824209,0.480516', '0.900805,0.244685', '-0.970103,0.134214', '-0.456163,0.843592', '-0.371109,0.938706', '1.741274,-0.190401', '1.334030,-0.421556', '1.031463,0.221893', '0.869790,0.622999', '1.055784,-0.454860', '0.946276,0.043335', '1.522766,-0.383962', '0.796718,-0.421524', '0.176834,-0.161574', '1.260869,-0.539424', '-0.819807,0.539398', '0.891035,-0.507779', '1.930084,0.277857', '-0.674109,0.719630', '1.863654,0.062468', '-0.094806,0.986424', '0.149966,1.059950', '1.944468,0.516037', '0.350379,-0.228188', '0.719153,-0.367313', '-0.121941,1.094255', '1.293216,-0.423305', '1.497917,-0.461778', '0.588864,0.771226', '-0.413680,0.909083', '0.195694,-0.099732', '-0.421523,0.830638', '-0.325394,0.980718', '-0.119789,0.932918', '-0.902580,0.370082', '1.611444,-0.235044', '0.193499,-0.037510', '-0.095974,1.010813', '-0.150082,0.994144', '2.078858,0.430012', '-0.426032,0.880905', '0.118620,0.128709', '0.491322,-0.225243', '0.634913,0.825075', '0.379752,0.922819', '-0.846450,0.512192', '0.276243,0.945285', '-0.158573,1.027251', '0.091232,0.354869', '-0.018585,0.951257', '0.036100,0.066044', '0.954727,-0.556080', '-0.340999,1.015456', '0.974570,-0.416102', '-0.011451,1.028321', '1.863401,0.098078', '-0.969564,0.540256', '-0.730363,0.583618', '1.299205,-0.453579', '0.173756,-0.100420', '0.432519,-0.427151', '-0.035315,0.993335', '-1.001975,0.321025', '-0.740656,0.685962', '1.909198,0.379926', '1.777583,-0.020409', '0.655463,-0.435345', '0.147873,1.040974', '0.025301,0.459533', '-1.043745,0.012310', '1.779321,-0.244509', '-1.043181,0.326600', '-0.997904,0.042038', '1.892066,0.072097', '-0.215596,0.987260', '0.366477,-0.305800', '-1.041247,0.128865', '0.124848,0.022081', '0.840194,0.584662', '-0.599606,0.763190', '0.388079,-0.290001', '1.278023,-0.473126', '1.639821,-0.249162', '0.793574,0.402214', '1.883348,-0.096953', '-0.463434,0.969253', '0.318336,-0.165906', '0.529140,-0.419901', '1.275509,-0.397563', '1.914986,0.244135', '0.219430,1.050104', '0.818744,0.600298', '0.124418,-0.016657', '-0.992666,0.240640', '0.007705,0.378926', '0.026350,0.971426', '-0.793296,0.654570', '0.063795,0.247558', '-0.754563,0.672200', '-0.977122,0.027071', '0.085911,0.455746', '1.257855,-0.553651', '1.727681,-0.137718', '0.697233,0.690763', '1.893240,0.209909', '1.056983,0.339418', '1.591099,-0.337685', '-0.584558,0.786539', '-0.234908,0.960451', '1.940357,0.055701', '0.237445,-0.109957', '-1.033752,0.061215', '0.401207,-0.233514', '0.153826,-0.039028', '0.811980,-0.455670', '0.997913,-0.517142', '0.226234,-0.242088', '-0.373124,0.893159', '0.982573,-0.030418', '0.038305,0.307536', '1.766021,-0.205980', '0.806889,0.564126', '0.153361,-0.188899', '-0.045101,0.328993', '0.001399,0.928675', '-0.243595,0.924408', '-0.899105,0.495534', '-0.775160,0.759127', '-0.795803,0.556095', '0.934860,0.321540', '0.991152,0.310529', '-0.072600,1.000246', '1.046287,0.256516', '-0.751816,0.540400', '1.130100,-0.476244', '1.970185,0.285139', '1.916669,0.442854', '-0.978045,0.307254', '-0.656887,0.770369', '1.662532,-0.293402', '-1.009811,0.067877', '0.217617,0.029234', '1.930655,0.377672', '0.599937,-0.405437', '1.675690,-0.229682', '1.833287,0.178134', '-0.675294,0.688389', '-0.455990,0.841012', '2.004386,0.193275', '-0.650523,0.771651', '-0.931306,0.526884', '1.997455,0.143432', '1.241722,-0.528982', '0.650585,0.843470', '1.404720,-0.401503', '-0.990227,0.090234', '0.967063,-0.539119', '-0.048900,0.940298', '0.402694,-0.228173', '1.707612,-0.179987', '0.591282,0.755066', '1.145884,-0.541822', '1.967950,0.563302', '-0.958322,0.149621', '-0.375088,0.906234', '2.009966,0.389455', '1.870094,0.029418', '0.802397,-0.487903', '-0.987343,0.306523', '1.145325,-0.571511', '0.300294,0.906508', '1.551385,-0.309974', '1.504266,-0.334533', '-0.843859,0.422667', '0.952111,0.079931', '1.148506,-0.471644', '0.547891,-0.371757', '0.854946,-0.444402', '0.274310,0.917037', '0.481294,-0.291184', '0.626517,0.900042', '0.591428,-0.403999', '0.052033,0.459594', '-0.441918,0.785610', '1.917696,0.419257', '1.508817,-0.431472', '0.304740,-0.124912', '1.376491,-0.423194', '0.014037,0.386851', '0.007442,0.418953', '1.931881,0.135330', '0.759216,0.652474', '0.220083,-0.230489', '0.938272,0.209516', '1.834793,-0.040413', '1.788192,-0.129739', '1.897847,0.495187', '0.513629,0.948086', '0.625786,0.904938', '0.938876,0.194624', '0.100354,-0.047422', '1.356815,-0.440283', '0.118053,-0.001990', '1.959104,0.262054', '-0.103693,1.006580', '-0.823577,0.582198', '-0.316758,0.905872', '0.168691,-0.095904', '-0.028115,0.333955', '0.940793,0.131420', '-0.803328,0.347589', '-0.021721,0.294792', '-0.335260,0.918399', '0.229068,-0.185832', '1.202745,-0.523575', '0.806400,0.346939', '0.819496,0.405233', '0.596530,-0.367667', '0.387457,0.883465', '0.961165,-0.459770', '0.334283,0.911829', '0.091338,0.334782', '-0.992455,0.065596', '0.353783,1.047730', '-0.704673,0.715047', '2.021483,0.419328', '-0.960760,0.301967', '-0.730468,0.808900', '0.985182,0.031101', '-0.898109,0.085922', '0.583132,-0.424688', '0.031447,0.967103', '0.427340,-0.364506', '0.867786,0.431580', '2.021659,0.312112', '0.819960,0.455634', '1.255875,-0.605225', '0.434069,-0.230737', '-0.907572,0.243372', '1.947390,-0.059693', '1.059459,0.224931', '1.991198,0.163752', '0.864715,-0.463920', '-0.891628,0.418780', '0.718582,0.796991', '1.487571,-0.418301', '0.229012,-0.079114', '1.014059,-0.501588', '-1.074043,0.084387', '-0.657417,0.949332', '-0.846894,0.592145', '0.859986,-0.445445', '0.027503,0.150645', '0.920867,0.353336', '0.536788,0.889764', '1.059237,-0.441490', '1.642919,-0.332419', '1.634017,-0.332254', '-0.046909,0.350500', '-0.992044,0.329474', '0.415042,0.838022', '1.971672,0.310047', '-0.511859,0.946377', '-0.593470,0.782506', '1.569043,-0.268114', '1.177611,-0.434771', '0.966866,0.276264', '1.646326,-0.297537', '1.669181,-0.247971', '0.545922,0.863368', '0.137786,1.043536', '0.334025,-0.326904', '0.169609,0.971153', '0.961763,-0.490990', '2.076352,0.330888', '0.681178,-0.456769', '0.459475,0.869157', '1.976015,0.479574', '1.950821,0.374261', '-1.032405,0.099716', '1.010003,0.066606', '0.823960,0.653654', '0.829471,0.481586', '-1.049362,0.139729', '-0.813446,0.566523', '-0.927441,0.387928', '-0.119301,0.994460', '1.485619,-0.450518', '1.837488,-0.179786', '-0.431415,0.923495', '1.363156,-0.313102', '1.921041,0.135859', '1.852019,0.119753', '-0.011740,0.354446', '0.941460,0.190968', '1.808835,-0.118383', '-0.735195,0.747718', '-0.873217,0.497412', '-0.162920,0.991178', '0.879718,0.344224', '1.000215,0.341356', '0.429582,0.858251', '-0.017167,0.432142', '1.941562,0.113316', '0.705378,0.657961', '-0.260711,0.984332', '0.921284,0.492477', '0.933780,0.355067', '-0.002407,0.518081', '-0.081028,0.921379', '1.291321,-0.378148', '1.650014,-0.303493', '1.068579,-0.503463', '0.930567,0.365394', '1.322731,-0.496713', '0.994623,0.299706', '-1.009303,0.350270', '0.663437,0.720942', '0.388485,-0.372178', '-0.863991,0.536639', '0.881015,-0.598020', '1.866221,0.178133', '-0.984703,0.153811', '0.740529,0.750580', '0.928154,0.003770', '0.567806,0.749225', '-0.484039,0.886955', '0.770050,0.685516', '0.879628,0.238361', '0.126224,0.965307', '0.070943,0.184671', '0.145707,0.956615', '0.136234,-0.082489', '-0.517019,0.802929', '1.922379,0.206370', '1.577593,-0.325829', '1.264758,-0.531197', '-0.460255,0.905094', '1.894081,-0.008216', '1.370319,-0.439508', '-0.554650,0.849810', '-0.662830,0.697644', '0.913560,0.034161', '0.338143,0.958028', '-0.803252,0.628068', '-0.568510,0.885438', '0.303967,0.987800', '1.951619,0.277315', '-0.519565,0.738620', '-0.383777,0.895284', '-0.068227,1.049508', '1.890204,-0.012463', '0.430686,0.872509', '0.380907,0.947814', '1.945512,0.150914', '0.682278,0.740357', '-0.257900,0.984931', '0.886852,-0.506633', '0.551719,-0.399865', '-0.425656,0.934872', '0.911320,0.484040', '0.007023,0.322343', '-0.539362,0.880596', '0.344303,0.954634', '1.725937,-0.227264', '0.176118,0.189637', '1.833597,0.000307', '0.086043,-0.119899', '-0.930049,0.243286', '1.085639,0.095389', '0.850198,-0.524466', '0.867950,-0.512460', '-0.029167,0.982554', '0.040257,0.950094', '0.025721,0.083745', '1.063161,0.238940', '0.888324,0.503129', '0.569018,0.833770', '-0.528059,0.911933', '1.444000,-0.270709', '-0.998567,0.108907', '0.529752,-0.319428', '0.693068,0.695959', '0.484737,-0.411373', '-0.698892,0.688944', '0.291272,-0.203729', '0.184993,-0.161733', '0.739555,0.521332', '-1.043270,0.263137', '0.395412,-0.315876', '1.385043,-0.383024', '1.618209,-0.281597', '-0.728679,0.594412', '0.128571,0.000402', '1.891693,0.496832', '-0.746928,0.582730', '0.224939,0.858917', '0.567624,0.861025', '0.391355,0.867368', '0.101418,0.932012', '0.419961,0.868623', '0.638637,-0.359677', '1.409845,-0.482429', '-0.608905,0.774982', '0.874950,-0.591899', '-1.064930,0.333358', '0.411922,-0.245928', '1.473916,-0.338779', '0.581790,0.901428', '-0.965076,0.134484', '0.208107,-0.075511', '2.011090,0.442275', '0.741939,0.640500', '1.026296,0.360422', '1.912583,-0.020505', '0.105365,0.519358', '0.091049,1.009565', '-0.004564,0.963023', '0.486664,0.814960', '1.308782,-0.437787', '0.220745,-0.204388', '0.554741,-0.441648', '0.424905,0.956642', '1.980895,0.179118', '-0.862820,0.545955', '0.783366,0.597786', '0.840608,-0.574644', '0.688277,-0.427390', '0.109941,0.939040', '-0.384107,0.875630', '0.325010,-0.256962', '0.693309,-0.438532', '1.736741,-0.189147', '-1.030451,0.119642', '1.878058,0.095012', '0.186622,0.932554', '-0.801591,0.644738', '1.820399,-0.032218', '-0.911651,0.362284', '-0.333202,0.981801', '1.170294,-0.485263', '1.795827,-0.161386', '0.953966,0.001908', '-0.922157,-0.044074', '0.051089,1.025620', '1.832270,-0.043298', '0.994807,0.017075', '0.209016,-0.168262', '-0.012893,0.276857', '-0.802970,0.537671', '0.856377,-0.456040', '1.668934,-0.252487', '0.587413,-0.479787', '0.741547,0.572216', '-0.336358,0.907714', '0.017973,0.246386', '0.905776,-0.456386', '0.257094,0.968247', '-0.288784,0.952953', '0.922985,0.296783', '0.881730,0.525711', '-0.624785,0.866846', '0.387806,-0.189713', '-0.878506,0.267726', '1.061790,0.191319', '-0.693009,0.688242', '-0.027153,0.212426', '-0.881176,0.293276', '0.211389,1.019098', '0.805286,-0.499159', '-0.016987,0.444793', '0.188814,-0.083733', '1.347667,-0.457559', '2.075242,0.157369', '0.580791,-0.401974', '0.230130,0.964909', '0.512810,-0.247113', '0.260056,0.966599', '-0.668751,0.805702', '0.472244,-0.281291', '-0.682047,0.733503', '0.348882,-0.187931', '0.433423,0.954100', '0.859405,-0.422572', '-0.799225,0.539377', '0.379718,0.932392', '0.092859,0.218967', '-0.750318,0.699036', '0.037765,0.269945', '0.463861,-0.349838', '-0.943041,0.347952', '0.579572,0.787517', '0.094542,1.024310', '0.490270,0.864137', '-0.927122,0.396667', '0.147060,-0.000282', '1.905488,0.265388', '1.204847,-0.560595', '0.302132,-0.203053', '0.852764,0.533023', '1.248003,-0.534833', '-1.033700,-0.013930', '0.957155,0.479306', '0.932117,0.483056', '0.314891,-0.078764', '0.962099,-0.129287', '-0.764163,0.686698', '-0.839787,0.182025', '1.335793,-0.411806', '0.041255,0.348762', '0.716451,0.655354', '0.661081,-0.461140', '0.287212,-0.193310', '0.213774,0.985725', '-0.493916,0.901987', '0.825878,0.597217', '0.667263,-0.480913', '-0.977788,0.082852', '0.160452,0.947567', '0.705686,0.719851', '0.012623,1.005656', '1.964698,0.337292', '1.769830,-0.137226', '0.268148,-0.186759', '1.351621,-0.434229', '-0.663824,0.802229', '1.406300,-0.529415', '0.963367,0.184822', '0.385876,-0.227482', '-0.802101,0.581797', '1.805776,-0.074872', '1.772058,0.011124', '1.023196,-0.055653', '0.673767,0.803494', '-0.602973,0.812647', '1.717049,-0.191814', '1.027073,-0.439656', '1.501234,-0.273513', '0.019000,0.112085', '1.849629,-0.182848', '0.315423,1.062312', '1.363681,-0.359651', '-0.634772,0.797334', '0.548533,-0.418638', '-0.546718,0.839064', '-0.836091,0.476189', '1.566145,-0.350613', '2.019942,0.203735', '-0.962633,0.293245', '0.907399,0.332531', '1.066078,-0.480579', '-0.646196,0.669292', '0.056448,0.915274', '0.832042,0.704119', '0.290947,-0.343560', '0.042950,0.295603', '0.744802,0.668949', '-0.065407,0.932997', '0.893429,-0.479021', '1.155565,-0.480938', '0.707472,0.832405', '1.014940,-0.006849', '0.005858,0.433484', '1.507557,-0.324207', '1.091748,-0.463062', '1.508009,-0.421659', '-0.879992,0.465922', '0.641586,-0.453083', '-0.614399,0.785258', '0.563814,0.894318', '0.060921,0.142418', '0.090628,0.218999', '-0.525554,0.775232', '1.834597,-0.139828', '2.020846,0.561365', '1.536839,-0.361871', '0.993866,0.449089', '-0.782169,0.583553', '0.084527,-0.010891', '-0.899180,0.080906', '-1.034229,0.229210', '0.458764,-0.307928', '0.494498,-0.388025', '0.020966,0.388384', '1.704726,-0.169185', '0.440941,-0.294465', '1.883686,0.030774', '-0.365824,0.932252', '0.559351,-0.394433', '0.464345,-0.304228', '0.115245,0.122447', '0.425012,0.751759', '-0.465560,0.884630', '0.896272,0.248930', '1.490060,-0.311304', '1.948545,0.118393', '-0.970133,0.059200', '1.218533,-0.480025', '-0.930415,0.304521', '0.676168,-0.426766', '-0.931366,0.470052', '0.110700,0.158821', '0.721567,-0.419036', '1.809006,-0.167602', '0.217574,0.988142', '0.546440,-0.310648', '0.093040,-0.044009', '-0.184088,1.011161', '-0.623403,0.730095', '0.615460,-0.397317', '0.941917,0.070579', '1.959408,0.412698', '-1.039415,0.204133', '1.111233,-0.514266', '0.630199,-0.451325', '1.767062,-0.237200', '-0.048060,0.407324', '0.132273,0.077721', '1.218557,-0.411402', '1.780223,-0.140967', '0.027655,0.290131', '1.828297,-0.118131', '-0.196738,0.984411', '-0.172174,0.994026', '-0.902462,0.048890', '-0.901773,0.438872', '-0.122171,1.019775', '0.727694,0.593145', '0.148432,-0.064693', '2.017855,0.354135', '0.947858,0.021173', '0.448597,-0.309842', '-0.971617,0.340677', '0.094180,-0.024800', '2.036363,0.278446', '0.550555,0.929095', '2.070986,0.348344', '1.944016,0.348548', '0.822089,-0.438202', '0.974903,-0.481873', '0.320873,0.996428', '0.385233,0.927434', '0.298531,-0.140841', '0.007273,0.274894', '1.723992,-0.258691', '0.513408,0.807346', '0.811352,0.551022', '1.003235,0.148958', '0.042377,0.089069', '1.892913,-0.047277', '0.841189,-0.361132', '-0.001176,0.228646', '-0.417805,0.848579', '-1.054033,0.137822', '-0.985072,-0.003544', '2.033992,0.290519', '-0.831660,0.563651', '1.009490,-0.501057', '0.807606,0.519351', '-0.970756,0.399318', '0.790746,0.529652', '1.587417,-0.315298', '1.856281,-0.017941', '0.464365,-0.338214', '-0.796690,0.498755', '0.463566,-0.441436', '2.017408,0.399870', '1.095537,-0.532518', '0.900372,-0.486944', '1.865523,-0.047228', '1.387849,-0.412363', '-0.414065,0.887199', '0.069130,0.177713', '-0.685842,0.848872', '0.937774,0.494194', '-0.021277,0.432763', '0.031081,0.484880', '-0.622480,0.857905', '0.176715,0.937435', '1.922691,0.039306', '0.562096,0.773854', '-0.216298,0.926206', '0.933576,0.306864', '0.760543,0.604478', '0.004798,0.428249', '1.363889,-0.492412', '2.028678,0.330911', '0.400218,0.885374', '0.404850,0.927816', '-0.592134,0.849195', '-0.768800,0.674436', '1.128810,-0.565910', '1.775059,-0.241308', '1.699416,-0.090247', '1.193367,-0.520811', '0.318067,0.932966', '0.602473,0.768028', '-0.909531,0.342595', '1.537608,-0.391712', '-0.040574,0.910068', '1.691553,-0.214751', '-0.267954,0.900214', '1.913732,0.160915', '1.932641,0.336614', '0.053581,1.079400', '0.350042,-0.235395', '1.071451,0.261010', '0.766989,0.673380', '0.987572,0.228074', '-0.491247,0.945978', '0.883849,0.295215', '2.053697,0.173982', '0.266025,1.006139', '-0.981570,0.494837', '0.942062,-0.501369', '-0.744100,0.622930', '0.871096,-0.474803', '-0.327155,1.002302', '0.894513,0.474002', '-0.834774,0.554555', '0.061390,0.134047', '0.155970,-0.027376', '-0.028284,0.239825', '1.610546,-0.286891', '1.447668,-0.469734', '1.630733,-0.422025', '0.469191,-0.460750', '0.193916,1.050988', '0.072596,0.201392', '1.443262,-0.403265', '0.224055,-0.249370', '0.553917,-0.332423', '1.464337,-0.410120', '-0.923528,0.434447', '0.692545,-0.420364', '0.676580,0.771100', '0.278767,0.993186', '0.305760,-0.164389', '1.536718,-0.380151', '1.490394,-0.371805', '1.660037,-0.300574', '0.901642,-0.495986', '1.981514,0.339083', '0.715724,-0.470504', '0.851021,-0.505891', '1.936443,-0.059066', '0.688181,-0.442644', '0.095509,1.008454', '1.027693,0.395715', '1.081272,0.185337', '-0.725715,0.708477', '0.160112,0.986605', '0.902883,-0.519234', '0.689988,0.745511', '-0.592390,0.860190', '0.682496,0.633049', '0.441702,0.942141', '0.203642,0.895642', '-0.988596,0.264154', '0.077951,0.131472', '-0.128848,1.024120', '1.928051,0.328902', '0.150575,-0.037775', '1.345135,-0.449742', '1.989666,0.078263', '0.071136,0.444845', '-0.068304,0.876122', '-1.033149,0.173602', '-0.434724,0.863541', '0.711183,0.719487', '1.938791,0.529644', '0.019266,0.456963', '0.144406,0.939650', '0.562255,-0.473916', '0.192698,-0.022335', '-0.999712,0.335082', '0.725338,0.637917', '-0.921728,0.194234', '1.162913,0.187027', '0.830144,0.653817', '0.545948,0.755359', '0.537725,0.835346', '-0.052854,0.359865', '0.655528,-0.406661', '0.285654,-0.238928', '-0.966995,0.239586', '0.187902,-0.128053', '0.658704,0.743580', '0.965270,-0.534168', '-0.001790,1.066666', '1.998760,0.268945', '-0.430616,0.945977', '1.783548,-0.146696', '-0.065725,1.049774', '-0.921526,0.283544', '-0.913598,0.494930', '0.258009,-0.114553', '0.973029,0.090313', '-0.502856,0.895570', '-0.264688,0.866823', '-0.083750,0.861275', '0.142893,1.042709', '0.844797,0.546940', '-0.033743,0.476901', '1.472948,-0.341593', '0.343756,-0.274198', '-0.260609,1.024673', '-0.194683,1.077622', '0.172597,-0.159392', '1.954589,0.127020', '-0.953538,0.349327', '0.416683,0.956685', '-0.641667,0.668964', '1.660976,-0.180677', '1.987992,0.414105', '-0.149492,1.007363', '1.239982,-0.404473', '1.934383,0.128107', '0.414313,0.990157', '0.983276,0.172491', '0.877076,0.542819', '-0.363646,1.019493', '1.099255,-0.487808', '1.029587,0.053967', '0.940795,0.173590', '0.931880,0.535030', '1.170773,-0.488482', '0.995979,0.260914', '1.962115,0.406007', '0.806504,0.277281', '1.009105,0.255610', '1.223133,-0.497627', '-0.904087,0.581649', '0.017976,0.119729', '0.186037,0.991574', '0.645463,0.748343', '0.902136,-0.543173', '0.179574,-0.096993', '0.738156,0.683388', '0.833083,-0.472425', '0.121387,-0.025215', '0.845286,0.528749', '-0.728912,0.655104', '0.718719,0.699329', '0.656070,-0.390387', '1.021468,0.199992', '1.702649,-0.175912', '0.051627,0.199152', '-0.693039,0.773888', '-0.003659,0.499722', '-0.775205,0.755628', '0.377512,0.893658', '-0.649628,0.656893', '0.090249,0.082553', '0.194755,-0.132083', '-0.746412,0.600841', '1.578812,-0.299606', '1.363399,-0.376444', '-0.287183,0.994841', '0.583117,-0.405665', '-0.034671,1.133501', '0.117413,-0.058656', '0.314549,0.968565', '0.837621,0.581594', '1.939584,0.161350', '1.929718,0.164931', '0.496712,0.816204', '0.127230,0.031182', '-0.265870,1.009603', '0.125491,0.191279', '1.597316,-0.243837', '-0.748880,0.661891', '0.828061,-0.485693', '1.358433,-0.533439', '0.161075,0.966801', '0.519192,-0.375590', '0.621922,0.779076', '1.585492,-0.206079', '0.401754,0.962702', '1.633201,-0.221605', '0.654828,0.751450', '1.911475,0.245710', '0.954913,0.276116', '1.180547,-0.473666', '-0.437405,0.969817', '0.329468,0.857104', '0.882146,0.483119', '0.377919,-0.309200', '0.138831,-0.011102', '0.348455,-0.140083', '-0.886235,0.516899', '1.850141,-0.141324', '0.822721,0.495079', '0.847345,0.613934', '-0.955640,0.447669', '1.266204,-0.508397', '0.706893,0.752762', '1.683220,-0.175217', '-0.202294,1.011537', '0.990209,0.351553', '-0.491173,0.918582', '-0.079558,0.996112', '1.811714,-0.202729', '1.982446,0.152220', '-0.903829,0.269714', '0.989880,0.285842', '0.288519,-0.094476', '-0.796029,0.678036', '-0.473515,0.848282', '-0.202646,0.966761', '1.033813,-0.502551', '-1.041467,0.090381', '-0.079714,0.152487', '1.840770,-0.049474', '0.862092,0.432106', '1.900492,0.150833', '1.919035,0.021775', '0.745542,0.628719', '1.488795,-0.440603', '0.949389,0.160445', '0.348224,0.930989', '1.738684,-0.230204', '-0.869009,0.203446', '0.069897,0.435334', '0.495355,-0.479106', '0.584773,0.763720', '0.029110,0.986894', '0.837577,-0.435440', '0.051218,0.147106', '0.125204,0.235407', '0.279551,-0.318349', '0.667608,-0.496383', '-0.148212,0.965253', '-0.263909,0.923455', '-0.856086,0.492804', '1.844226,-0.014438', '0.591966,0.685888', '0.423010,-0.357379', '1.317400,-0.460431', '2.005666,0.327178', '0.425073,0.846800', '0.871745,0.704731', '1.613002,-0.331514', '-0.970347,0.363795', '-0.901539,0.459708', '1.644702,-0.344633', '0.723470,-0.423589', '1.135602,-0.512684', '0.695305,0.715821', '1.855883,-0.038987', '1.138470,-0.497840', '0.963663,0.340880', '1.521787,-0.412908', '0.036521,0.257236', '0.506546,-0.268265', '1.509152,-0.323184', '1.949079,0.340663', '0.457723,0.888057', '0.905884,0.517687', '0.169893,0.227482', '-1.015718,-0.028188', '0.803421,-0.455314', '-0.376814,0.960147', '-0.737538,0.595316', '0.159509,-0.148824', '-1.014829,0.084445', '0.869135,0.452557', '0.195657,-0.034296', '1.284400,-0.452684', '0.950364,-0.450975', '-0.157296,0.916191', '0.817563,-0.532960', '1.029598,0.014936', '-0.672452,0.779371', '0.729492,-0.535363', '1.005174,-0.415974', '1.530638,-0.247243', '0.333445,0.946734', '0.325150,-0.328385', '0.097571,0.118347', '0.570815,-0.445340']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0 11 14 ... 12 11 12]\n",
      " [11  0 13 ... 12 12 12]\n",
      " [14 13  0 ... 10 12 13]\n",
      " ...\n",
      " [12 12 10 ...  0 11 10]\n",
      " [11 12 12 ... 11  0 10]\n",
      " [12 12 13 ... 10 10  0]]\n"
     ]
    }
   ],
   "source": [
    "def discretise_dataset(filename,bins):\n",
    "    df = pd.read_csv(filename, sep = ',', header = None) \n",
    "    oneColumn = np.array(df[1])\n",
    "    for i in range(2,df.shape[1]):\n",
    "        oneColumn=np.append(oneColumn,np.array(df[i]))\n",
    "    dfoneColumn=pd.DataFrame(oneColumn)\n",
    "    nb_bins=bins\n",
    "    dftemp=pd.DataFrame()\n",
    "    dftemp[0]=pd.cut(dfoneColumn[0], bins=nb_bins, labels=np.arange(nb_bins), right=False)\n",
    "    df_new=pd.DataFrame(df[0])\n",
    "    nb_tuples=df.shape[0]\n",
    "    j=0\n",
    "    for i in range(1,df.shape[1]):\n",
    "        df_new[i]=np.copy(dftemp[0][j:j+nb_tuples])\n",
    "        j+=nb_tuples\n",
    "    return df_new\n",
    "    \n",
    "# test de la fonction    \n",
    "df=discretise_dataset('iris_8_10_8_/iris_l1_8.csv',5)\n",
    "print (df.head())\n",
    "print (df.tail())\n",
    "\n",
    "#Exemple d'utilisation de la mesure de levenstein\n",
    "#pip install python-levenshtein\n",
    "from Levenshtein import distance\n",
    "print (distance('3,10,0,4,0,0,9,0', '4,8,0,2,0,0,8,0'))\n",
    "\n",
    "#Creation d'une matrice de distance\n",
    "df_mat=pd.DataFrame(X)\n",
    "string=\"toto.csv\"\n",
    "df_mat.to_csv(string, sep=',', encoding='utf-8',index=False, header=False)\n",
    "df_mat=pd.read_csv(string, sep = ',', header = None)\n",
    "#recuperation de la matrice sous la forme de chaine\n",
    "ch = df_mat.to_string(header=False,\n",
    "                  index=False,\n",
    "                  index_names=False).split('\\n')\n",
    "vals = [','.join(ele.split()) for ele in ch]\n",
    "print (vals)    \n",
    "\n",
    "\n",
    "\n",
    "List1 = vals\n",
    "List2 = vals\n",
    "Matrix = np.zeros((len(List1),len(List2)),dtype=np.int)\n",
    "\n",
    "for i in range(0,len(List1)):\n",
    "    for j in range(0,len(List2)):\n",
    "        Matrix[i,j] = distance(List1[i],List2[j])\n",
    "\n",
    "print (Matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
